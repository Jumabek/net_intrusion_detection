{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vtu3TZYmXNlY",
        "outputId": "671a6579-14d6-4089-a0f3-0f25cd3769f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'net_intrusion_detection' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/Jumabek/net_intrusion_detection.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d9H1suspcZco",
        "outputId": "28f6c744-acfa-40bb-81b4-2896ab1cc2f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/net_intrusion_detection\n"
          ]
        }
      ],
      "source": [
        "%cd /content/net_intrusion_detection"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git checkout transformer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VH_7jiesm8Ve",
        "outputId": "2a015498-2bc5-4c47-d85d-ad69b1628545"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Already on 'transformer'\n",
            "Your branch is up to date with 'origin/transformer'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X4rH1Hqbcb9D",
        "outputId": "72fb4efc-d947-4b23-96ce-4f3e96b22f91"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gdown/cli.py:121: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1-t3RdDpmqMs4ABt9oobSapeNYTZJ9tpu\n",
            "To: /content/net_intrusion_detection/MachineLearningCSV.zip\n",
            "100% 235M/235M [00:01<00:00, 165MB/s]\n"
          ]
        }
      ],
      "source": [
        "!gdown --id 1-t3RdDpmqMs4ABt9oobSapeNYTZJ9tpu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MnwMJi9dcb6t",
        "outputId": "8fde150b-7f48-4f26-f2c6-14df8364592d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  MachineLearningCSV.zip\n",
            "replace MachineLearningCVE/Wednesday-workingHours.pcap_ISCX.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: N\n"
          ]
        }
      ],
      "source": [
        "!unzip MachineLearningCSV.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "VZT4APPQcb4N"
      },
      "outputs": [],
      "source": [
        "from preprocessing import read_data\n",
        "\n",
        "def load_data(dataroot):\n",
        "    data = read_data(dataroot, '*.pcap_ISCX.csv')\n",
        "    num_records, num_features = data.shape\n",
        "    print(f\"There are {num_records} flow records with {num_features} feature dimensions\")\n",
        "\n",
        "    data = data.rename(columns=lambda x: x.strip())  # Strip whitespace from column names\n",
        "    return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zk1jAPNecb09",
        "outputId": "1728b8fb-3b1e-4e41-8029-270bae1304d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MachineLearningCVE/*.pcap_ISCX.csv\n",
            "['MachineLearningCVE/Friday-WorkingHours-Afternoon-DDos.pcap_ISCX.csv', 'MachineLearningCVE/Thursday-WorkingHours-Afternoon-Infilteration.pcap_ISCX.csv', 'MachineLearningCVE/Tuesday-WorkingHours.pcap_ISCX.csv', 'MachineLearningCVE/Friday-WorkingHours-Morning.pcap_ISCX.csv', 'MachineLearningCVE/Monday-WorkingHours.pcap_ISCX.csv', 'MachineLearningCVE/Thursday-WorkingHours-Morning-WebAttacks.pcap_ISCX.csv', 'MachineLearningCVE/Friday-WorkingHours-Afternoon-PortScan.pcap_ISCX.csv', 'MachineLearningCVE/Wednesday-workingHours.pcap_ISCX.csv']\n",
            "There are 2830743 flow records with 79 feature dimensions\n"
          ]
        }
      ],
      "source": [
        "data = load_data('MachineLearningCVE/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "evtntzg2do3f"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import  LabelEncoder\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "wwLWbGG1cbye"
      },
      "outputs": [],
      "source": [
        "non_numeric_columns = data.columns.drop('Label')  \n",
        "data[non_numeric_columns] = data[non_numeric_columns].apply(pd.to_numeric, errors='coerce')\n",
        "\n",
        "data.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "data = data.dropna()\n",
        "\n",
        "num_columns = non_numeric_columns.tolist()\n",
        "\n",
        "X = data.drop(\"Label\", axis=1)\n",
        "y = data[\"Label\"]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from preprocessing import balance_data, normalize\n",
        "X = normalize(X)\n",
        "X = X.to_numpy()"
      ],
      "metadata": {
        "id": "KScGpbYk4rjk"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "J1Dar0XCcbvx"
      },
      "outputs": [],
      "source": [
        "# Preprocess the labels\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_fHWXusGIkbh",
        "outputId": "db529a39-28c5-4924-c3d8-843011736195"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2271320,    1956,  128025,   10293,  230124,    5499,    5796,\n",
              "          7935,      11,      36,  158804,    5897,    1507,      21,\n",
              "           652])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "unique_classes, counts = np.unique(y, return_counts=True)\n",
        "\n",
        "counts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "liEuO-fEcbng"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "GWkq7w9TcbaM"
      },
      "outputs": [],
      "source": [
        "class IDS2017Dataset(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.X = torch.tensor(X, dtype=torch.float32)\n",
        "        self.y = torch.tensor(y, dtype=torch.long)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx], self.y[idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "Ac9Qs-snc0wT"
      },
      "outputs": [],
      "source": [
        "class IDS2017Transformer(nn.Module):\n",
        "    def __init__(self, input_dim, d_model, nhead, num_layers, num_classes):\n",
        "        super(IDS2017Transformer, self).__init__()\n",
        "        self.embedding = nn.Linear(input_dim, d_model)\n",
        "        self.transformer = nn.Transformer(d_model, nhead, num_layers)\n",
        "        self.classifier = nn.Linear(d_model, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x)\n",
        "        x = self.transformer.encoder(x.unsqueeze(1))\n",
        "        x = x.squeeze(1)\n",
        "        x = self.classifier(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "lNVMMyGQfuv5"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader, Subset\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "dataset = IDS2017Dataset(X,y_encoded)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "GwxN_DqIc4Tj"
      },
      "outputs": [],
      "source": [
        "n_splits = 5\n",
        "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YG6xRksudBjl",
        "outputId": "99e5f07b-f321-4bd0-a722-3c4bfadc8947"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1:\n",
            "Epoch [1/20], Loss: 0.2177\n",
            "Epoch [2/20], Loss: 0.0886\n",
            "Epoch [3/20], Loss: 0.0660\n",
            "Epoch [4/20], Loss: 0.0535\n",
            "Epoch [5/20], Loss: 0.0470\n",
            "Epoch [6/20], Loss: 0.0838\n",
            "Epoch [7/20], Loss: 0.0475\n",
            "Epoch [8/20], Loss: 0.0430\n",
            "Epoch [9/20], Loss: 0.0449\n",
            "Epoch [10/20], Loss: 0.0408\n",
            "Epoch [11/20], Loss: 0.0398\n",
            "Epoch [12/20], Loss: 0.0390\n",
            "Epoch [13/20], Loss: 0.0399\n",
            "Epoch [14/20], Loss: 0.0396\n",
            "Epoch [15/20], Loss: 0.0373\n",
            "Epoch [16/20], Loss: 0.0367\n",
            "Epoch [17/20], Loss: 0.0364\n",
            "Epoch [18/20], Loss: 0.0358\n",
            "Epoch [19/20], Loss: 0.0412\n",
            "Epoch [20/20], Loss: 0.0421\n",
            "balanced test acc:  45.28964682854525\n",
            "Fold 2:\n",
            "Epoch [1/20], Loss: 0.2097\n",
            "Epoch [2/20], Loss: 0.0865\n",
            "Epoch [3/20], Loss: 0.0646\n",
            "Epoch [4/20], Loss: 0.0530\n",
            "Epoch [5/20], Loss: 0.0501\n",
            "Epoch [6/20], Loss: 0.0455\n",
            "Epoch [7/20], Loss: 0.0428\n",
            "Epoch [8/20], Loss: 0.0412\n",
            "Epoch [9/20], Loss: 0.0744\n",
            "Epoch [10/20], Loss: 0.0488\n",
            "Epoch [11/20], Loss: 0.0431\n",
            "Epoch [12/20], Loss: 0.0410\n",
            "Epoch [13/20], Loss: 0.0396\n",
            "Epoch [14/20], Loss: 0.0390\n",
            "Epoch [15/20], Loss: 0.0382\n",
            "Epoch [16/20], Loss: 0.0376\n",
            "Epoch [17/20], Loss: 0.0374\n",
            "Epoch [18/20], Loss: 0.0390\n",
            "Epoch [19/20], Loss: 0.0368\n",
            "Epoch [20/20], Loss: 0.0366\n",
            "balanced test acc:  42.794161552352186\n",
            "Fold 3:\n",
            "Epoch [1/20], Loss: 0.1992\n",
            "Epoch [2/20], Loss: 0.0850\n",
            "Epoch [3/20], Loss: 0.0755\n",
            "Epoch [4/20], Loss: 0.0540\n",
            "Epoch [5/20], Loss: 0.0482\n",
            "Epoch [6/20], Loss: 0.0446\n",
            "Epoch [7/20], Loss: 0.0426\n",
            "Epoch [8/20], Loss: 0.0468\n",
            "Epoch [9/20], Loss: 0.0403\n",
            "Epoch [10/20], Loss: 0.0393\n",
            "Epoch [11/20], Loss: 0.0389\n",
            "Epoch [12/20], Loss: 0.0383\n",
            "Epoch [13/20], Loss: 0.0370\n",
            "Epoch [14/20], Loss: 0.0368\n",
            "Epoch [15/20], Loss: 0.0363\n",
            "Epoch [16/20], Loss: 0.0371\n",
            "Epoch [17/20], Loss: 0.0356\n",
            "Epoch [18/20], Loss: 0.0359\n",
            "Epoch [19/20], Loss: 0.0356\n",
            "Epoch [20/20], Loss: 0.0343\n",
            "balanced test acc:  52.44997813388872\n",
            "Fold 4:\n",
            "Epoch [1/20], Loss: 0.2131\n",
            "Epoch [2/20], Loss: 0.0872\n",
            "Epoch [3/20], Loss: 0.0747\n",
            "Epoch [4/20], Loss: 0.0546\n",
            "Epoch [5/20], Loss: 0.0485\n",
            "Epoch [6/20], Loss: 0.0441\n",
            "Epoch [7/20], Loss: 0.0450\n",
            "Epoch [8/20], Loss: 0.0414\n",
            "Epoch [9/20], Loss: 0.0395\n",
            "Epoch [10/20], Loss: 0.0393\n",
            "Epoch [11/20], Loss: 0.0385\n",
            "Epoch [12/20], Loss: 0.0375\n",
            "Epoch [13/20], Loss: 0.0396\n",
            "Epoch [14/20], Loss: 0.0363\n",
            "Epoch [15/20], Loss: 0.0365\n",
            "Epoch [16/20], Loss: 0.0358\n",
            "Epoch [17/20], Loss: 0.0530\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import balanced_accuracy_score,classification_report, f1_score, recall_score, accuracy_score, precision_score\n",
        "\n",
        "num_epochs = 20\n",
        "\n",
        "results = {}\n",
        "\n",
        "for fold, (train_idx, test_idx) in enumerate(skf.split(X, y_encoded)):\n",
        "    train_dataset = Subset(dataset, train_idx)\n",
        "    test_dataset = Subset(dataset, test_idx)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=8*1024, shuffle=True, num_workers=4)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=8*1024, shuffle=False, num_workers=4)\n",
        "\n",
        "    model = IDS2017Transformer(input_dim=X.shape[1], d_model=64, nhead=4, num_layers=2, num_classes=len(y.unique())).to(device)\n",
        "    model.to(device)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    print(f\"Fold {fold + 1}:\")\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        for i, (inputs, labels) in enumerate(train_loader):\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {running_loss / len(train_loader):.4f}')\n",
        "    model.eval()\n",
        "    y_true, y_pred = [], []\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            y_true.extend(labels.cpu().numpy())\n",
        "            y_pred.extend(predicted.cpu().numpy())\n",
        "    test_acc = balanced_accuracy_score(y_true,y_pred)*100\n",
        "    print('balanced test acc: ',test_acc)\n",
        "    results[fold]= (test_acc)i\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mU0AHiXxR6AQ"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}