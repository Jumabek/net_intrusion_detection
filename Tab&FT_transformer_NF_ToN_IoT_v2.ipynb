{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##Importing the necessary libraries"
      ],
      "metadata": {
        "id": "uCG7vclesIzM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Zg8K_8J3NE2q"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, accuracy_score, brier_score_loss, roc_auc_score, average_precision_score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tab-transformer-pytorch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DFJZU59gYASn",
        "outputId": "55e5ffa8-569b-4401-bed9-27c7ae36aa26"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tab-transformer-pytorch\n",
            "  Downloading tab_transformer_pytorch-0.3.0-py3-none-any.whl (6.9 kB)\n",
            "Collecting einops>=0.3 (from tab-transformer-pytorch)\n",
            "  Downloading einops-0.7.0-py3-none-any.whl (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=1.6 in /usr/local/lib/python3.10/dist-packages (from tab-transformer-pytorch) (2.1.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->tab-transformer-pytorch) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->tab-transformer-pytorch) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->tab-transformer-pytorch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->tab-transformer-pytorch) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->tab-transformer-pytorch) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->tab-transformer-pytorch) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->tab-transformer-pytorch) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6->tab-transformer-pytorch) (2.1.4)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6->tab-transformer-pytorch) (1.3.0)\n",
            "Installing collected packages: einops, tab-transformer-pytorch\n",
            "Successfully installed einops-0.7.0 tab-transformer-pytorch-0.3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set a fixed random seed for reproducibility across all relevant libraries and operations."
      ],
      "metadata": {
        "id": "dtgAVl0LtBhK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def set_seed(seed):\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "    # Ensuring that PyTorch's convolution operations are deterministic\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "\n",
        "set_seed(42)"
      ],
      "metadata": {
        "id": "E43P5R3Xf4ZS"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading and Preprocessing the NF Ton IoT v2 Dataset:"
      ],
      "metadata": {
        "id": "6boWvBt6tpMy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Downloading the Dataset\n",
        "!gdown --id 1JNsyqlCwT8IVudqj3yZ1y6wgbG7me5Pq\n",
        "!unzip /content/NF-ToN-IoT-v2.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IuehK8yjgozi",
        "outputId": "79148e81-c32c-479b-dd5d-16b24bbc6afb"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gdown/cli.py:138: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1JNsyqlCwT8IVudqj3yZ1y6wgbG7me5Pq\n",
            "From (redirected): https://drive.google.com/uc?id=1JNsyqlCwT8IVudqj3yZ1y6wgbG7me5Pq&confirm=t&uuid=bc656982-f12d-4fe0-b3fc-bf74432b0734\n",
            "To: /content/NF-ToN-IoT-v2.zip\n",
            "100% 185M/185M [00:03<00:00, 53.3MB/s]\n",
            "Archive:  /content/NF-ToN-IoT-v2.zip\n",
            "  inflating: NF-ToN-IoT-v2/NetFlow_v2_Features.csv  \n",
            "  inflating: NF-ToN-IoT-v2/NF-ToN-IoT-v2.csv  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading the NF-ToN-IoT-v2 dataset from a CSV file into a DataFrame. This process takes approximately 46 seconds.\n",
        "df_whole = pd.read_csv(\"/content/NF-ToN-IoT-v2/NF-ToN-IoT-v2.csv\")\n",
        "\n",
        "# Dropping specific columns from the DataFrame that are not required for the analysis.\n",
        "# These include 'Attack', 'IPV4_SRC_ADDR', 'IPV4_DST_ADDR', and certain byte-related columns.\n",
        "df_whole = df_whole.drop(columns=[\"Attack\",\"IPV4_SRC_ADDR\", \"IPV4_DST_ADDR\",\"SRC_TO_DST_SECOND_BYTES\",\"DST_TO_SRC_SECOND_BYTES\"])\n",
        "\n",
        "# Converting all columns in the DataFrame to float type for consistency and to facilitate numerical operations.\n",
        "df = df_whole.astype(float)\n",
        "\n",
        "# Reducing the dataset size by randomly sampling 0.1% of the data to make the dataset more manageable and speed up computations.\n",
        "# The random state is set to 42 for reproducibility.\n",
        "df = df.sample(frac=0.001, random_state=42)"
      ],
      "metadata": {
        "id": "G-Wky3oqgxBE"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "# Assuming df is your loaded DataFrame\n",
        "categorical_columns = ['PROTOCOL', 'ICMP_TYPE', 'ICMP_IPV4_TYPE', 'DNS_QUERY_ID', 'DNS_QUERY_TYPE', 'FTP_COMMAND_RET_CODE']\n",
        "continuous_columns = [col for col in df.columns if col not in categorical_columns + ['Label']]\n",
        "\n",
        "# Convert categorical columns to type 'category'\n",
        "for col in categorical_columns:\n",
        "    df[col] = df[col].astype('category')\n",
        "\n",
        "# Extract features and target\n",
        "X_categorical = df[categorical_columns].apply(lambda x: x.cat.codes).values\n",
        "X_continuous = df[continuous_columns].values\n",
        "y = df['Label'].values\n",
        "\n",
        "# Normalization for continuous features only\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X_continuous = scaler.fit_transform(X_continuous)\n",
        "\n",
        "# Splitting the data\n",
        "X_cat_train, X_cat_test, X_cont_train, X_cont_test, y_train, y_test = train_test_split(X_categorical, X_continuous, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Convert to PyTorch tensors\n",
        "X_cat_train_tensor = torch.tensor(X_cat_train, dtype=torch.long)\n",
        "X_cont_train_tensor = torch.tensor(X_cont_train, dtype=torch.float32)\n",
        "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
        "\n",
        "X_cat_test_tensor = torch.tensor(X_cat_test, dtype=torch.long)\n",
        "X_cont_test_tensor = torch.tensor(X_cont_test, dtype=torch.float32)\n",
        "y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n"
      ],
      "metadata": {
        "id": "NfxP8Ybn6sVG"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_device():\n",
        "    return 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "device = get_device()"
      ],
      "metadata": {
        "id": "5WFh3gk4kKDu"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TabTransformer(nn.Module):\n",
        "    def __init__(self, num_continuous, num_classes, num_embeddings_list, embedding_dim=32, num_transformer_layers=6, transformer_heads=8, transformer_forward_dim=128, dropout_rate=0.1):\n",
        "        super(TabTransformer, self).__init__()\n",
        "\n",
        "        # Embeddings for categorical features\n",
        "        self.embeddings = nn.ModuleList([nn.Embedding(n_e, embedding_dim) for n_e in num_embeddings_list])\n",
        "\n",
        "        # Continuous feature linear layer\n",
        "        self.continuous_linear = nn.Linear(num_continuous, embedding_dim * len(num_embeddings_list))\n",
        "\n",
        "        # Transformer\n",
        "        transformer_layer = nn.TransformerEncoderLayer(d_model=embedding_dim * len(num_embeddings_list), nhead=transformer_heads, dim_feedforward=transformer_forward_dim, dropout=dropout_rate)\n",
        "        self.transformer_encoder = nn.TransformerEncoder(transformer_layer, num_layers=num_transformer_layers)\n",
        "\n",
        "        # Final classifier\n",
        "        self.fc = nn.Linear(embedding_dim * len(num_embeddings_list), num_classes)\n",
        "\n",
        "    def forward(self, x_cat, x_cont):\n",
        "        embeddings = [embedding(x_cat[:, i]) for i, embedding in enumerate(self.embeddings)]\n",
        "        x = torch.cat(embeddings, dim=1) + self.continuous_linear(x_cont)\n",
        "\n",
        "        x = self.transformer_encoder(x.unsqueeze(1)).squeeze(1)\n",
        "        x = self.fc(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "# Model instantiation\n",
        "num_embeddings_list = [df[col].nunique() for col in categorical_columns]\n",
        "embedding_dim = 32\n",
        "num_continuous = len(continuous_columns)\n",
        "num_classes = len(df['Label'].unique())\n",
        "\n",
        "# model = TabTransformer(num_continuous, num_classes, num_embeddings_list, embedding_dim)\n",
        "# model = model.to(device)\n",
        "\n",
        "# Example setup for DataLoader\n",
        "train_dataset = TensorDataset(X_cat_train_tensor, X_cont_train_tensor, y_train_tensor)  # Ensure tensors are correctly prepared\n",
        "train_loader = DataLoader(train_dataset, batch_size=512, shuffle=True)\n",
        "test_dataset = TensorDataset(X_cat_test_tensor, X_cont_test_tensor, y_test_tensor)  # Ensure tensors are correctly prepared\n",
        "test_loader = DataLoader(test_dataset, batch_size=512, shuffle=True)\n"
      ],
      "metadata": {
        "id": "M5OV_OoihBta"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import torch\n",
        "from tab_transformer_pytorch import TabTransformer\n",
        "\n",
        "# Assuming the device setup and tensors have been defined as per the previous steps\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Model Configuration and Instantiation\n",
        "# Note: Adjust categories based on your actual dataset\n",
        "categories = tuple([int(df[col].nunique()) for col in categorical_columns])\n",
        "num_continuous = X_cont_train_tensor.shape[1]  # Number of continuous features in your data\n",
        "\n",
        "model = TabTransformer(\n",
        "    categories=categories,               # Tuple with the number of unique values per categorical feature\n",
        "    num_continuous=num_continuous,       # Number of continuous values\n",
        "    dim=32,                               # Dimension, paper set at 32\n",
        "    dim_out=1,                            # Output dimension, 1 for binary classification\n",
        "    depth=6,                              # Depth, paper recommended 6\n",
        "    heads=8,                              # Heads, paper recommends 8\n",
        "    attn_dropout=0.1,                     # Post-attention dropout\n",
        "    ff_dropout=0.1,                       # Feed-forward dropout\n",
        "    mlp_hidden_mults=(4, 2),              # Relative multiples of each hidden dimension of the last MLP to logits\n",
        "    mlp_act=nn.ReLU(),                    # Activation for final MLP\n",
        ").to(device)\n",
        "\n",
        "loss_function = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()  # Set the model to training mode\n",
        "    running_loss = 0.0\n",
        "    for i, (cat_features, cont_features, labels) in enumerate(train_loader):\n",
        "        cat_features, cont_features, labels = cat_features.to(device), cont_features.to(device), labels.to(device)\n",
        "\n",
        "        # Zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(cat_features, cont_features)\n",
        "\n",
        "        # Compute loss\n",
        "        loss = loss_function(outputs, labels.float().unsqueeze(1))  # Ensure labels are the correct shape and type\n",
        "        loss.backward()  # Compute gradient of the loss with respect to model parameters\n",
        "        optimizer.step()  # Perform a single optimization step\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss / len(train_loader):.4f}')\n"
      ],
      "metadata": {
        "id": "q-09N3hChJM8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd27f93b-b64d-43a3-b78e-66e8260d5556"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 0.4551\n",
            "Epoch [2/10], Loss: 0.2716\n",
            "Epoch [3/10], Loss: 0.1997\n",
            "Epoch [4/10], Loss: 0.1494\n",
            "Epoch [5/10], Loss: 0.1233\n",
            "Epoch [6/10], Loss: 0.1041\n",
            "Epoch [7/10], Loss: 0.0868\n",
            "Epoch [8/10], Loss: 0.0833\n",
            "Epoch [9/10], Loss: 0.0790\n",
            "Epoch [10/10], Loss: 0.0669\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, roc_auc_score, precision_recall_curve, auc, brier_score_loss\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "model.eval()  # Set the model to evaluation mode\n",
        "true_labels = []\n",
        "scores = []\n",
        "\n",
        "with torch.no_grad():  # Disable gradient computation\n",
        "    for cat_features, cont_features, labels in test_loader:\n",
        "        cat_features, cont_features, labels = cat_features.to(device), cont_features.to(device), labels.to(device)\n",
        "        outputs = model(cat_features, cont_features)\n",
        "\n",
        "        # Assuming the output is a logit for binary classification, apply sigmoid to get probabilities\n",
        "        probs = torch.sigmoid(outputs).squeeze().cpu().numpy()\n",
        "        scores.extend(probs)\n",
        "\n",
        "        true_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "# Convert probabilities to binary predictions based on a 0.5 threshold\n",
        "predictions = np.array(scores) > 0.5\n",
        "\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(true_labels, predictions, zero_division=0))\n",
        "\n",
        "roc_auc = roc_auc_score(true_labels, scores)\n",
        "print(f\"AUC-ROC: {roc_auc:.4f}\")\n",
        "\n",
        "precision, recall, _ = precision_recall_curve(true_labels, scores)\n",
        "auc_pr = auc(recall, precision)\n",
        "print(f\"AUC-PR: {auc_pr:.4f}\")\n",
        "\n",
        "brier_score = brier_score_loss(true_labels, scores)\n",
        "print(f\"Brier score: {brier_score:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qbcpFd8ZlEG_",
        "outputId": "ddc53c75-f478-49f6-b9bf-7b070be0c163"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.93      0.95      1206\n",
            "           1       0.96      0.99      0.97      2182\n",
            "\n",
            "    accuracy                           0.97      3388\n",
            "   macro avg       0.97      0.96      0.96      3388\n",
            "weighted avg       0.97      0.97      0.97      3388\n",
            "\n",
            "AUC-ROC: 0.9825\n",
            "AUC-PR: 0.9837\n",
            "Brier score: 0.0285\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from tab_transformer_pytorch import FTTransformer\n",
        "\n",
        "# Example setup for DataLoader\n",
        "train_dataset = TensorDataset(X_cat_train_tensor, X_cont_train_tensor, y_train_tensor)  # Ensure tensors are correctly prepared\n",
        "train_loader = DataLoader(train_dataset, batch_size=512, shuffle=True)\n",
        "\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "model = FTTransformer(\n",
        "    categories = categories,      # tuple containing the number of unique values within each category\n",
        "    num_continuous = num_continuous,                # number of continuous values\n",
        "    dim = 32,                           # dimension, paper set at 32\n",
        "    dim_out = 1,                        # binary prediction, but could be anything\n",
        "    depth = 6,                          # depth, paper recommended 6\n",
        "    heads = 8,                          # heads, paper recommends 8\n",
        "    attn_dropout = 0.1,                 # post-attention dropout\n",
        "    ff_dropout = 0.1                    # feed forward dropout\n",
        ")\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = model.to(device)\n",
        "\n",
        "loss_function = nn.BCEWithLogitsLoss()  # Assuming binary classification\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for batch in train_loader:\n",
        "        x_categ, x_numer, y = [item.to(device) for item in batch]\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(x_categ, x_numer).squeeze(1)\n",
        "        loss = loss_function(outputs, y.float())\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "    print(f'Epoch {epoch+1}, Loss: {total_loss / len(train_loader)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fMRvXg4NlRi9",
        "outputId": "9a3fcaf0-8466-435f-8f1c-4712cd423411"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 0.5710726689409327\n",
            "Epoch 2, Loss: 0.4314321356791037\n",
            "Epoch 3, Loss: 0.4529719253381093\n",
            "Epoch 4, Loss: 0.37532821628782487\n",
            "Epoch 5, Loss: 0.3593967612142916\n",
            "Epoch 6, Loss: 0.30663899580637616\n",
            "Epoch 7, Loss: 0.1947062247329288\n",
            "Epoch 8, Loss: 0.14395135309961107\n",
            "Epoch 9, Loss: 0.12496594808719776\n",
            "Epoch 10, Loss: 0.11667687914989612\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, roc_auc_score, precision_recall_curve, auc, brier_score_loss\n",
        "\n",
        "model.eval()\n",
        "true_labels = []\n",
        "scores = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in test_loader:\n",
        "        x_categ, x_numer, labels = [item.to(device) for item in batch]\n",
        "        outputs = model(x_categ, x_numer).squeeze(1)\n",
        "        probs = torch.sigmoid(outputs).cpu().numpy()\n",
        "        scores.extend(probs)\n",
        "        true_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "predictions = np.array(scores) > 0.5\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(true_labels, predictions, zero_division=0))\n",
        "\n",
        "roc_auc = roc_auc_score(true_labels, scores)\n",
        "print(f\"AUC-ROC: {roc_auc:.4f}\")\n",
        "\n",
        "precision, recall, _ = precision_recall_curve(true_labels, scores)\n",
        "auc_pr = auc(recall, precision)\n",
        "print(f\"AUC-PR: {auc_pr:.4f}\")\n",
        "\n",
        "brier_score = brier_score_loss(true_labels, scores)\n",
        "print(f\"Brier score: {brier_score:.4f}\")\n"
      ],
      "metadata": {
        "id": "RWebk3nXq7vH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4821e63a-c789-495f-b130-35c56a409c22"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.90      0.93      1206\n",
            "           1       0.95      0.98      0.96      2182\n",
            "\n",
            "    accuracy                           0.95      3388\n",
            "   macro avg       0.96      0.94      0.95      3388\n",
            "weighted avg       0.95      0.95      0.95      3388\n",
            "\n",
            "AUC-ROC: 0.9830\n",
            "AUC-PR: 0.9886\n",
            "Brier score: 0.0362\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dG08zwI6VtOL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}